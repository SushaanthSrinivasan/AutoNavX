{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sushaanth\\anaconda3\\envs\\lsa_clone\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from C:\\Users\\Sushaanth\\.cache\\huggingface\\hub\\models--ShilongLiu--GroundingDINO\\snapshots\\a94c9b567a2a374598f05c584e96798a170c56fb\\groundingdino_swinb_cogcoor.pth \n",
      " => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import groundingdino.datasets.transforms as T\n",
    "import numpy as np\n",
    "import torch\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util import box_ops\n",
    "from groundingdino.util.inference import predict\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
    "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
    "\n",
    "    args = SLConfig.fromfile(cache_config_file)\n",
    "    model = build_model(args)\n",
    "    args.device = device\n",
    "\n",
    "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "    checkpoint = torch.load(cache_file, map_location='cpu')\n",
    "    log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
    "    print(f\"Model loaded from {cache_file} \\n => {log}\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def transform_image(image) -> torch.Tensor:\n",
    "    transform = T.Compose([\n",
    "        T.RandomResize([800], max_size=1333),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    image_transformed, _ = transform(image, None)\n",
    "    return image_transformed\n",
    "\n",
    "\n",
    "def plot_boxes(image, boxes):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        box_width = x_max - x_min\n",
    "        box_height = y_max - y_min\n",
    "        rect = patches.Rectangle((x_min, y_min), box_width, box_height,\n",
    "                                  linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        # ax.text(x_min, y_min, phrase, color='r', fontsize=12, verticalalignment='top')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class GDino():\n",
    "    def __init__(self, return_prompts: bool = False):\n",
    "        self.return_prompts = return_prompts\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.build_groundingdino()\n",
    "\n",
    "    def build_groundingdino(self):\n",
    "        ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "        ckpt_filename = \"groundingdino_swinb_cogcoor.pth\"\n",
    "        ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\"\n",
    "        self.groundingdino = load_model_hf(ckpt_repo_id, ckpt_filename, ckpt_config_filename)\n",
    "\n",
    "    def predict_dino(self, image_pil, text_prompt, box_threshold, text_threshold):\n",
    "        image_trans = transform_image(image_pil)\n",
    "        boxes, logits, phrases = predict(model=self.groundingdino,\n",
    "                                         image=image_trans,\n",
    "                                         caption=text_prompt,\n",
    "                                         box_threshold=box_threshold,\n",
    "                                         text_threshold=text_threshold,\n",
    "                                        #  remove_combined=self.return_prompts, # modified\n",
    "                                         device=self.device)\n",
    "        W, H = image_pil.size\n",
    "        boxes = box_ops.box_cxcywh_to_xyxy(boxes) * torch.Tensor([W, H, W, H])\n",
    "\n",
    "        # return boxes, logits, phrases\n",
    "        return boxes\n",
    "\n",
    "    def predict(self, image_pil, text_prompt, box_threshold=0.3, text_threshold=0.25):\n",
    "        boxes = self.predict_dino(image_pil, text_prompt, box_threshold, text_threshold)\n",
    "        return boxes\n",
    "\n",
    "model = GDino()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.921921968460083 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "prompt = 'cube'\n",
    "\n",
    "image_pil = Image.open(\"./captured_images/20240519-152936649981.png\").convert(\"RGB\")\n",
    "boxes = model.predict(image_pil, prompt)\n",
    "# plot_boxes(image_pil, boxes)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "prompt = 'cube'\n",
    "image_pil = Image.open(\"./captured_images/20240519-152939714675.png\").convert(\"RGB\")\n",
    "boxes = model.predict(image_pil, prompt)\n",
    "# plot_boxes(image_pil, boxes)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsa_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
